<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Istio 生态 | 云原生资料库</title>
    <link>https://jimmysong.io/docs/istio-handbook/ecosystem/</link>
      <atom:link href="https://jimmysong.io/docs/istio-handbook/ecosystem/index.xml" rel="self" type="application/rss+xml" />
    <description>Istio 生态</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Wed, 18 May 2022 00:00:00 +0800</lastBuildDate>
    <image>
      <url>https://jimmysong.io/docs/media/logo.svg</url>
      <title>Istio 生态</title>
      <link>https://jimmysong.io/docs/istio-handbook/ecosystem/</link>
    </image>
    
    <item>
      <title>Aeraki</title>
      <link>https://jimmysong.io/docs/istio-handbook/ecosystem/aeraki/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0800</pubDate>
      <guid>https://jimmysong.io/docs/istio-handbook/ecosystem/aeraki/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/aeraki-mesh/aeraki&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aeraki&lt;/a&gt; 是腾讯云在 2021 年 3 月开源的一个服务网格领域的项目。Aeraki 提供了一个端到端的云原生服务网格协议扩展解决方案，以一种非侵入的方式为 Istio 提供了强大的第三方协议扩展能力，支持在 Istio 中对 Dubbo、Thrift、Redis，以及对私有协议进行流量管理。Aeraki 的架构如下图所示：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-aeraki架构图&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../images/aeraki-arch.png&#34; alt=&#34;Aeraki架构图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Aeraki架构图
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;来源：&lt;a href=&#34;https://istio.io/latest/blog/2021/aeraki/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://istio.io/latest/blog/2021/aeraki/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;从 Aeraki 架构图中可以看到，Aeraki 协议扩展解决方案包含了两个组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Aeraki：Aeraki 作为一个 Istio 增强组件运行在控制面，通过自定义 CRD 向运维提供了用户友好的流量规则配置。Aeraki 将这些流量规则配置翻译为 Envoy 配置，通过 Istio 下发到数据面的 sidecar 代理上。Aeraki 还作为一个 RDS 服务器为数据面的 MetaProtocol Proxy 提供动态路由。Aeraki 提供的 RDS 和 Envoy 的 RDS 有所不同，Envoy RDS 主要为 HTTP 协议提供动态路由，而 Aeraki RDS 旨在为所有基于 MetaProtocol 框架开发的七层协议提供动态路由能力。&lt;/li&gt;
&lt;li&gt;MetaProtocol Proxy：基于 Envoy 实现的一个通用七层协议代理。依托 Envoy 成熟的基础库，MetaProtocol Proxy 是在 Envoy 代码基础上的扩展。它为七层协议统一实现了服务发现、负载均衡、RDS 动态路由、流量镜像、故障注入、本地 / 全局限流等基础能力，大大降低了在 Envoy 上开发第三方协议的难度，只需要实现编解码的接口，就可以基于 MetaProtocol 快速开发一个第三方协议插件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果没有使用 MetaProtocol Proxy，要让 Envoy 识别一个七层协议，则需要编写一个完整的 TCP filter，这个 filter 需要实现路由、限流、遥测等能力，需要投入大量的人力。对于大部分的七层协议来说，需要的流量管理能力是类似的，因此没有必要在每个七层协议的 filter 实现中重复这部分工作。Aeraki 项目采用了一个 MetaProtocol Proxy 来统一实现这些能力，如下图所示：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-metaprotocol-proxy-架构图&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../images/metaprotocol-proxy.png&#34; alt=&#34;MetaProtocol Proxy 架构图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      MetaProtocol Proxy 架构图
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;基于 MetaProtocol Proxy，只需要实现编解码接口部分的代码就可以编写一个新的七层协议 Envoy Filter。除此之外，无需添加一行代码，Aeraki 就可以在控制面提供该七层协议的配置下发和 RDS 动态路由配置。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-采用-metaprotocol-编写-envoy-filter-的对比&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../images/metaprotocol-proxy-codec.png&#34; alt=&#34;采用 MetaProtocol 编写 Envoy Filter 的对比&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      采用 MetaProtocol 编写 Envoy Filter 的对比
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Aeraki + MetaProtocol 套件降低了在 Istio 中管理第三方协议的难度，将 Istio 扩展成为一个支持所有协议的全栈服务网格。目前 Aeraki 项目已经基于 MetaProtocol 实现了 Dubbo 和 Thrift 协议。相对 Envoy 自带的 Dubbo 和 Thrift Filter，基于 MetaProtocol 的 Dubbo 和 Thrift 实现功能更为强大，提供了 RDS 动态路由，可以在不中断存量链接的情况下对流量进行高级的路由管理，并且提供了非常灵活的 Metadata 路由机制，理论上可以采用协议数据包中携带的任意字段进行路由。QQ 音乐和央视频 APP 等业务也正在基于 Aeraki 和 MetaProtocol 进行开发，以将一些私有协议纳入到服务网格中进行管理。&lt;/p&gt;
&lt;p&gt;除此之外，&lt;a href=&#34;https://github.com/aeraki-mesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aeraki&lt;/a&gt; 中还提供了 xDS 配置下发优化的 lazyXDS 插件、Consul、etcd、Zookeeper 等各种第三方服务注册表对接适配，Istio 运维实战电子书等工具，旨在解决 Istio 在落地中遇到的各种实际问题，加速服务网格的成熟和产品化。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/aeraki-mesh/aeraki&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aeraki GitHub - github.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Slime</title>
      <link>https://jimmysong.io/docs/istio-handbook/ecosystem/slime/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0800</pubDate>
      <guid>https://jimmysong.io/docs/istio-handbook/ecosystem/slime/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/slime-io/slime/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime&lt;/a&gt; 是由网易数帆微服务团队开源的一款基于 Istio 的智能网格管理器。Slime 基于 Kubernetes Operator 实现，可作为 Istio 的 CRD 管理器，无须对 Istio 做任何定制化改造，就可以定义动态的服务治理策略，从而达到自动便捷使用 Istio 和 Envoy 高阶功能的目的。&lt;/p&gt;
&lt;h2 id=&#34;slime-试图解决的问题&#34;&gt;Slime 试图解决的问题&lt;/h2&gt;
&lt;p&gt;Slime 项目的诞生主要为了解决以下问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;网格内所有服务配置全量下到所有 Sidecar Proxy，导致其消耗大量资源使得应用性能变差的问题&lt;/li&gt;
&lt;li&gt;如何在 Istio 中实现高阶扩展的问题：比如扩展 HTTP 插件；根据服务的资源使用率做到自适应限流&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Slime 解决以上问题的答案是构建 Istio 的控制平面，具体做法是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;构建可拔插控制器&lt;/li&gt;
&lt;li&gt;数据平面监控&lt;/li&gt;
&lt;li&gt;CRD 转换&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过以上方式 Slime 可以实现&lt;strong&gt;配置懒加载&lt;/strong&gt;和&lt;strong&gt;插件管理器&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;slime-架构&#34;&gt;Slime 架构&lt;/h2&gt;
&lt;p&gt;Slime 内部分为三大模块，其架构图如下所示。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-slime-内部架构图&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../images/slime-internal-arch.jpg&#34; alt=&#34;Slime 内部架构图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Slime 内部架构图
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Slime 内部三大组件为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;slime-boot&lt;/code&gt;：在 Kubernetes 上部署 Slime 模块的 operator。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;slime-controller&lt;/code&gt;：Slime 的核心组件，监听 Slime CRD 并将其转换为Istio CRD。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;slime-metric&lt;/code&gt;：用于获取服务 metrics 信息的组件，&lt;code&gt;slime-controller&lt;/code&gt; 会根据其获取的信息动态调整服务治理规则。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;目前 Slime 内置了三个控制器子模块：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;配置懒加载（按需加载）&lt;/strong&gt;：用户无须手动配置 &lt;code&gt;SidecarScope&lt;/code&gt;，Istio 可以按需加载服务配置和服务发现信息；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP 插件管理&lt;/strong&gt;：使用新的 CRD——&lt;code&gt;pluginmanager/envoyplugin&lt;/code&gt; 包装了可读性，摒弃了可维护性较差的 &lt;code&gt;envoyfilter&lt;/code&gt;，使得插件扩展更为便捷；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自适应限流&lt;/strong&gt;：结合监控信息自动调整限流策略；&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;什么是 SidecarScope？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SidecarScope 是在 Istio 1.1 版本中引入的，它并不是一个直接面向用户的配置项，而是 Sidecar 资源的包装器，具体来说就是 &lt;a href=&#34;../../config-networking/sidecar/&#34;&gt;Sidecar 资源&lt;/a&gt;中的 &lt;code&gt;egress&lt;/code&gt; 选项。通过该配置可以减少 Istio 向 Sidecar 下发的数据量，例如只向某个命名空间中的某些服务下发某些 hosts 的访问配置，从而提高应用提高性能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;使用-slime-作为-istio-的控制平面&#34;&gt;使用 Slime 作为 Istio 的控制平面&lt;/h2&gt;
&lt;p&gt;为了解决这些问题，Slime 在 Istio 之上构建了更高层次的抽象，相当于为 Istio 构建了一层管理平面，其工作流程图如下所示。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-slime-工作流程图&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../images/slime-flow-chart.jpg&#34; alt=&#34;Slime 工作流程图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Slime 工作流程图
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;具体步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Slime Operator 根据管理员的配置在 Kubernetes 中完成 Slime 组件的初始化；&lt;/li&gt;
&lt;li&gt;开发者创建符合 Slime CRD 规范的配置并应用到 Kubernetes 集群中；&lt;/li&gt;
&lt;li&gt;Slime 查询 Prometheus 中保存的相关服务的监控数据，结合 Slime CRD 中自适应部分的配置，将 Slime CRD 转换为 Istio CRD，同时将其推送到 Global Proxy 中；&lt;/li&gt;
&lt;li&gt;Istio 监听 Istio CRD 的创建；&lt;/li&gt;
&lt;li&gt;Istio 将 Sidecar Proxy 的配置信息推送到数据平面相应的 Sidecar Proxy 中；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上只是一个对 Slime 工作流程的一个笼统的介绍，更多详细信息请参考 &lt;a href=&#34;https://github.com/slime-io/slime/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime GitHub&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;配置懒加载&#34;&gt;配置懒加载&lt;/h2&gt;
&lt;p&gt;为了解决数据平面中 Sidecar Proxy 资源消耗过大及网络延迟问题，Slime 使用了配置懒加载（按需加载 Sidecar 配置）的方案。该方案的核心思想是向每个 Sidecar Proxy 中只下发其所 Pod 中服务所需的配置，而不是将网格中的所有服务信息全量下发。所以 Slime 需要获取每个服务的调用关系这样才能得到其所需的 Sidecar Proxy 配置。&lt;/p&gt;
&lt;p&gt;Slime 实现 Sidecar Proxy 配置懒加载的方法是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;让数据平面中的所有服务的首次调用都通过一个 Global Proxy，该 Proxy 可以记录所有服务的调用和依赖信息，根据该依赖信息更新 Istio 中 Sidecar 资源的配置；&lt;/li&gt;
&lt;li&gt;当某个服务的调用链被 VirtualService 中的路由信息重新定义时， Global Proxy 原有记录就失效了，需要一个新的数据结构来维护该服务的调用关系。Slime 创建了名为 &lt;code&gt;ServiceFence&lt;/code&gt;  的 CRD 来维护服务调用关系以解决服务信息缺失问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;使用-global-proxy-初始化服务调用拓扑&#34;&gt;使用 Global Proxy 初始化服务调用拓扑&lt;/h3&gt;
&lt;p&gt;Slime 在数据平面中部署 Global Proxy（也叫做 Global Sidecar，但其与应用的 Pod 不是一对一的关系，笔者更倾向于称其为 Global Proxy），该代理同样使用 Envoy 构建，在每个需要启动配置懒加载的命名空间中部署一个或在整个网格中只部署一个，所有缺失服务发现信息的调用（你也可以手动配置服务调用关系），都会被兜底路由劫持到 Global Proxy，经过其首次转发后，Slime 便可感知到被调用方的信息，然后根据其对应服务的 VirtualService，找到服务名和真实后端的映射关系，将两者的都加入 SidecarScope，以后该服务的调用就不再需要经过 Global Proxy 了。&lt;/p&gt;
&lt;h3 id=&#34;使用-servicefence-维护服务调用拓扑&#34;&gt;使用 ServiceFence 维护服务调用拓扑&lt;/h3&gt;
&lt;p&gt;在使用 Global Proxy 初始化服务调用拓扑后，一旦服务调用链有变动的话怎么办？对此 Slime 创建了 ServiceFence 的 CRD。使用 ServiceFence 可以维护服务名和后端服务的映射关系。Slime 根据其对应服务的 VirtualService，找到 Kubernetes 服务名和真实后端（host）的映射关系，将两者的都加入 Sidecar 的配置中。ServiceFence 管理生成的 SidecarScope 的生命周期，自动清理长时间不用的调用关系，从而避免上述问题。&lt;/p&gt;
&lt;h3 id=&#34;如何开启配置懒加载&#34;&gt;如何开启配置懒加载&lt;/h3&gt;
&lt;p&gt;配置懒加载功能对于终端用户是透明的，只需要 Kubernetes  Service 上打上 &lt;code&gt;istio.dependency.servicefence/status:&amp;quot;true&amp;quot;&lt;/code&gt; 的标签，表明该服务需要开启配置懒加载，剩下的事情交给 Slime Operator 来完成即可。&lt;/p&gt;
&lt;h2 id=&#34;http-插件管理&#34;&gt;HTTP 插件管理&lt;/h2&gt;
&lt;p&gt;Istio 中的插件扩展只能通过 EnvoyFilter 来实现，因为它是 xDS 层面的配置，管理和维护这样的配置需要耗费大量的精力，也极容易出错。因此，Slime 在 EnvoyFilter 的基础上做了一层面向插件的抽象。&lt;/p&gt;
&lt;p&gt;Slime 共有两个 CRD 用于 HTTP 插件管理，分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PluginManager&lt;/strong&gt;：配置为哪些负载开启哪些插件，插件的配置顺序即为执行顺序；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EnvoyPlugin&lt;/strong&gt;：EnvoyPlugin 不关心每个插件的具体配置，具体配置会被放在 EnvoyFilter 资源的 &lt;code&gt;patch.typed_config&lt;/code&gt; 结构中透传），EnvoyPlugin 的核心思想是将插件配置在需要的维度中做聚合，从而限定插件的生鲜范围。这样做一方面更加贴合插件使用者的习惯，另一方面也降低了上层配置的冗余，&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;自适应限流&#34;&gt;自适应限流&lt;/h2&gt;
&lt;p&gt;Envoy 内置的限流组件功能单一，只能以实例维度配置限流值，无法做到根据应用负载的自适应限流。Slime 通过与 Prometheus metric server 对接，实时的获取监控情况，来动态配置限流值。&lt;/p&gt;
&lt;p&gt;Slime 自适应限流的流程图如下所示。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-slime-的自适应限流流程图&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../images/slime-smart-limiter.jpg&#34; alt=&#34;Slime 的自适应限流流程图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Slime 的自适应限流流程图
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Slime 的自适应限流的流程分为两部分，一部分为 SmartLimiter 到 EnvoyFilter 的转换，另一部分为获取监控数据。目前 Slime 支持从 Kubernetes Metric Server 获取服务的CPU、内存、副本数等数据。Slime 还对外提供了一套监控数据接口（Metric Discovery Server），通过 MDS，可以将自定义的监控指标同步给限流组件。&lt;/p&gt;
&lt;p&gt;Slime 创建的 CRD &lt;code&gt;SmartLimiter&lt;/code&gt; 用于配置自适应限流。其的配置是接近自然语义，例如希望在 CPU 超过 80% 时触发服务 A 的访问限制，限额为 30QPS，对应的SmartLimiter 定义如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;microservice.netease.com/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;SmartLimiter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;descriptors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fill_interval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;seconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;quota&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;30/{pod}&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 30为该服务的额度，将其均分给每个 pod，加入有 3 个 pod，则每个 pod 的限流为 10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;condition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{cpu}&amp;gt;0.8&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 根据监控项{cpu}的值自动填充该模板&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;更多&#34;&gt;更多&lt;/h2&gt;
&lt;p&gt;Slime 开源于 2021 年初，本文发稿时该项目仍处于初级阶段，本文大量参考了杨笛航在云原生社区中的分享 &lt;a href=&#34;https://cloudnative.to/blog/netease-slime/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime：让 Istio 服务网格变得更加高效与智能&lt;/a&gt; 及 Slime 的 &lt;a href=&#34;https://github.com/slime-io/slime&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;。感兴趣的读者可以关注下这个项目的 GitHub，进一步了解它。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/netease-slime/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime：让 Istio 服务网格变得更加高效与智能 - cloudnative.to&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/slime-io/slime/blob/master/README_ZH.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime GitHub 文档 - github.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/sidecar/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sidecar - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Merbridge</title>
      <link>https://jimmysong.io/docs/istio-handbook/ecosystem/merbridge/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0800</pubDate>
      <guid>https://jimmysong.io/docs/istio-handbook/ecosystem/merbridge/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/merbridge/merbridge&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Merbridge&lt;/a&gt; 是由 DaoCloud 在 2022 年初开源的的一款利用 eBPF 加速 Istio 服务网格的插件。使用 Merbridge 可以在一定程度上优化数据平面的网络性能。&lt;/p&gt;
&lt;h2 id=&#34;使用条件&#34;&gt;使用条件&lt;/h2&gt;
&lt;p&gt;要想使用 Merbridge，你的系统必须满足以下条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Istio 网格中的主机使用 Linux 5.7 及以上版本内核&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;
&lt;p&gt;在 &lt;a href=&#34;../../concepts/transparent-traffic-hijacking/&#34;&gt;Istio 中的透明流量劫持详解&lt;/a&gt;中，我们谈到 Istio 默认使用 IPtables 拦截数据平面中的流量到 Envoy 代理，这种拦截方式通用性最强。因为 Pod 中所有的 inbound 和 outbound 流量都会先通过 Envoy 代理，尤其是 Pod 接收的流量，都要先通过 IPtables 将流量劫持到 Envoy 代理后再发往 Pod 中的应用容器的端口。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-使用-iptables-劫持流量发到当前-pod-的应用端口&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../images/to-localhost.png&#34; alt=&#34;使用 IPtables 劫持流量发到当前 Pod 的应用端口&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      使用 IPtables 劫持流量发到当前 Pod 的应用端口
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;利用 eBPF 的 sockops 和 redir 能力，可以直接将数据包从 inbound socket 传输到 outbound socket。eBPF 提供了 &lt;code&gt;bpf_msg_redirect_hash&lt;/code&gt; 函数可以直接转发应用程序的数据包。&lt;/p&gt;
&lt;p&gt;下图展示的是在不同主机上的 Pod 的利用 eBPF 来劫持流量的示意图。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-使用-merbridge-的在不同主机上的-pod&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../images/diff-host.png&#34; alt=&#34;使用 Merbridge 的在不同主机上的 Pod&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      使用 Merbridge 的在不同主机上的 Pod
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Pod 内部的流量劫持使用的是 Merbridge，而不同主机间依然需要使用 IPtables 来转发流量。&lt;/p&gt;
&lt;p&gt;如果两个 Pod 位于同一台主机，那么流量转发全程都可以通过 Merbridge 完成。下图展示了的是在同一主机上使用 Merbridge 的示意图。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-使用-merbridge-的同一个主机上的-pod&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../images/same-host.png&#34; alt=&#34;使用 Merbridge 的同一个主机上的 Pod&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      使用 Merbridge 的同一个主机上的 Pod
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;关于 Merbridge 原理的详细解释请参考 &lt;a href=&#34;https://istio.io/latest/blog/2022/merbridge/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio 文档&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;如何使用&#34;&gt;如何使用&lt;/h2&gt;
&lt;p&gt;只需要在 Istio 集群执行一条命令，即可直接使用 eBPF 代替 iptables 做透明流量拦截，实现网络加速。而且这对 Istio 是无感的，你可以随时安装和卸载 Merbridge。使用下面的命令启用 Merbridge：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f https://raw.githubusercontent.com/merbridge/merbridge/main/deploy/all-in-one.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Merbridge 是以 DaemonSet 的方式运行在 Istio 网格的每个节点上。它运行在服务网格的下层，对于 Istio 是透明的，要启用它时，无需对 Istio 做任何改动。&lt;/p&gt;
&lt;p&gt;如果你想删除 Merbridge，请运行下面的命令：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl delete -f https://raw.githubusercontent.com/merbridge/merbridge/main/deploy/all-in-one.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/blog/2022/merbridge/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Merbridge - Accelerate your mesh with eBPF - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&#34;cta-group&#34;&gt;
  
  &lt;li&gt;
    &lt;a href=&#34;../../practice/&#34;  class=&#34;btn btn-primary px-3 py-3&#34;&gt;下一章&lt;/a&gt;
  &lt;/li&gt;
  
  
&lt;/ul&gt;

</description>
    </item>
    
  </channel>
</rss>
