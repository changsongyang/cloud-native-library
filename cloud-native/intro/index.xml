<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>关于云原生 | 云原生资料库</title>
    <link>https://jimmysong.io/docs/cloud-native/intro/</link>
      <atom:link href="https://jimmysong.io/docs/cloud-native/intro/index.xml" rel="self" type="application/rss+xml" />
    <description>关于云原生</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Sun, 09 Sep 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://jimmysong.io/docs/media/logo_hu217dae2ad2bcd8acb156327d70759d70_15430_300x300_fit_lanczos_3.png</url>
      <title>关于云原生</title>
      <link>https://jimmysong.io/docs/cloud-native/intro/</link>
    </image>
    
    <item>
      <title>什么是云原生？</title>
      <link>https://jimmysong.io/docs/cloud-native/intro/what-is-cloud-native/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0100</pubDate>
      <guid>https://jimmysong.io/docs/cloud-native/intro/what-is-cloud-native/</guid>
      <description>&lt;p&gt;云原生（Cloud Native）这个词汇由来已久，以致于何时出现已无据可考。云原生开始大规模出现在受众视线中，与 Pivotal 提出的云原生应用的理念有着莫大的关系。我们现在谈到云原生，更多的指的是&lt;a href=&#34;https://cloudnative.to/blog/cloud-native-culture-not-container/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一种文化&lt;/a&gt;，而不具象为哪些技术体系。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Pivotal 推出过 Pivotal Cloud Foundry 云原生应用平台和 &lt;a href=&#34;https://spring.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Spring&lt;/a&gt; 开源 Java 开发框架，成为云原生应用架构中先驱者和探路者。Pivotal 是云原生应用平台第一股，2018 年在纽交所上市，2019 年底被 VMWare 以 27 亿美元收购，加入到 VMware 新的产品线 &lt;a href=&#34;https://tanzu.vmware.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tanzu&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;pivotal-最初的定义&#34;&gt;Pivotal 最初的定义&lt;/h2&gt;
&lt;p&gt;早在 2015 年 Pivotal 公司的 Matt Stine 写了一本叫做 &lt;a href=&#34;https://jimmysong.io/migrating-to-cloud-native-application-architectures/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;迁移到云原生应用架构&lt;/a&gt; 的小册子，其中探讨了云原生应用架构的几个主要特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;符合 12 因素应用&lt;/li&gt;
&lt;li&gt;面向微服务架构&lt;/li&gt;
&lt;li&gt;自服务敏捷架构&lt;/li&gt;
&lt;li&gt;基于 API 的协作&lt;/li&gt;
&lt;li&gt;抗脆弱性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;笔者已于 2017 年翻译了本书，详见 &lt;a href=&#34;https://jimmysong.io/migrating-to-cloud-native-application-architectures/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;迁移到云原生应用架构&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;cncf-最初的定义&#34;&gt;CNCF 最初的定义&lt;/h2&gt;
&lt;p&gt;到了 2015 年 Google 主导成立了云原生计算基金会（CNCF），起初 CNCF 对云原生（Cloud Native）的定义包含以下三个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用容器化&lt;/li&gt;
&lt;li&gt;面向微服务架构&lt;/li&gt;
&lt;li&gt;应用支持容器的编排调度&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;重定义&#34;&gt;重定义&lt;/h2&gt;
&lt;p&gt;到了 2018 年，随着近几年来云原生生态的不断壮大，所有主流云计算供应商都加入了该基金会，且从 &lt;a href=&#34;https://i.cncf.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Native Landscape&lt;/a&gt; 中可以看出云原生有意蚕食原先非云原生应用的部分。CNCF 基金会中的会员以及容纳的项目越来越多，该定义已经限制了云原生生态的发展，CNCF 为云原生进行了重新定位。&lt;/p&gt;
&lt;p&gt;以下是 CNCF 对云原生的&lt;a href=&#34;https://github.com/cncf/toc/blob/main/DEFINITION.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;重新定义&lt;/a&gt;（中英对照）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式 API。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Cloud Native Computing Foundation seeks to drive adoption of this paradigm by fostering and sustaining an ecosystem of open source, vendor-neutral projects. We democratize state-of-the-art patterns to make these innovations accessible for everyone.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;云原生计算基金会（CNCF）致力于培育和维护一个厂商中立的开源生态系统，来推广云原生技术。我们通过将最前沿的模式民主化，让这些创新为大众所用。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;关于什么是云原生的争论还在进行中，在笔者看来云原生是一种行为方式和设计理念，究其本质，凡是能够提高云上资源利用率和应用交付效率的行为或方式都是云原生的。云计算的发展史就是一部云原生化的历史。Kubernetes 开启了云原生的序幕，服务网格 Istio 的出现，引领了后 Kubernetes 时代的微服务，serverless 的再次兴起，使得云原生从基础设施层不断向应用架构层挺进，我们正处于一个云原生的新时代。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cncf/toc/blob/master/DEFINITION.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF Cloud Native Definition v1.0 - github.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/cloud-native-culture-not-container/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生关乎文化，而不是容器 - cloudnative.to&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>云原生的设计哲学</title>
      <link>https://jimmysong.io/docs/cloud-native/intro/cloud-native-philosophy/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0100</pubDate>
      <guid>https://jimmysong.io/docs/cloud-native/intro/cloud-native-philosophy/</guid>
      <description>&lt;p&gt;云原生一词已经被过度的采用，很多软件都号称是云原生，很多打着云原生旗号的会议也如雨后春笋般涌现。&lt;/p&gt;
&lt;p&gt;云原生本身甚至不能称为是一种架构，它首先是一种基础设施，运行在其上的应用称作云原生应用，只有符合云原生设计哲学的应用架构才叫云原生应用架构。&lt;/p&gt;
&lt;h2 id=&#34;云原生的设计理念&#34;&gt;云原生的设计理念&lt;/h2&gt;
&lt;p&gt;云原生系统的设计理念如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;面向分布式设计（Distribution）：容器、微服务、API 驱动的开发；&lt;/li&gt;
&lt;li&gt;面向配置设计（Configuration）：一个镜像，多个环境配置；&lt;/li&gt;
&lt;li&gt;面向韧性设计（Resistancy）：故障容忍和自愈；&lt;/li&gt;
&lt;li&gt;面向弹性设计（Elasticity）：弹性扩展和对环境变化（负载）做出响应；&lt;/li&gt;
&lt;li&gt;面向交付设计（Delivery）：自动拉起，缩短交付时间；&lt;/li&gt;
&lt;li&gt;面向性能设计（Performance）：响应式，并发和资源高效利用；&lt;/li&gt;
&lt;li&gt;面向自动化设计（Automation）：自动化的 DevOps；&lt;/li&gt;
&lt;li&gt;面向诊断性设计（Diagnosability）：集群级别的日志、metric 和追踪；&lt;/li&gt;
&lt;li&gt;面向安全性设计（Security）：安全端点、API Gateway、端到端加密；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上的设计理念很多都是继承自分布式应用的设计理念。虽然有如此多的理念但是我们仍然无法辨认什么样的设施才是云原生基础设施，不过可以先用排除法，我将解释什么不是云原生基础设施。&lt;/p&gt;
&lt;h2 id=&#34;什么不是云原生基础设施&#34;&gt;什么不是云原生基础设施？&lt;/h2&gt;
&lt;p&gt;云原生基础设施不等于在公有云上运行的基础设施。光是租用服务器并不会使您的基础设施云原生化。管理 IaaS 的流程与运维物理数据中心没什么两样，将现有架构迁移到云上也未必能获得回报。&lt;/p&gt;
&lt;p&gt;云原生不是指在容器中运行应用程序。Netflix 率先推出云原生基础设施时，几乎所有应用程序部署在虚拟机中，而不是在容器中。改变应用程序的打包方式并不意味着就会增加自治系统的可扩展性和优势。即使应用程序是通过 CI/CD 渠道自动构建和部署的，也不意味着您就可以从增强 API 驱动部署的基础设施中受益。&lt;/p&gt;
&lt;p&gt;这也并不意味着您只能运行容器编排器（例如 Kubernetes 和 Mesos）。容器编排器提供了云原生基础设施所需的许多平台功能，但并未按预期方式使用这些功能，这意味着您的应用程序会在一组服务器上运行，被动态调度。这是一个非常好的起步，但仍有许多工作要做。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;调度器与编排器&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;术语 “调度器” 和 “编排器” 通常可以互换使用。&lt;/p&gt;
&lt;p&gt;在大多数情况下，编排器负责集群中的所有资源利用（例如：存储，网络和 CPU）。该术语典型地用于描述执行许多任务的产品，如健康检查和云自动化。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;调度器是编排平台的一个子集，仅负责选择运行在每台服务器上的进程和服务。&lt;/p&gt;
&lt;p&gt;云原生不是微服务或基础设施即代码。微服务意味着更快的开发周期和更小的独特功能，但是单体应用程序可以具有相同的功能，使其能够通过软件有效管理，并且还可以从云原生基础设施中受益。&lt;/p&gt;
&lt;p&gt;基础设施即代码以机器可解析语言或领域特定语言（DSL）定义、自动化您的基础设施。将代码应用于基础架构的传统工具包括配置管理工具（例如 Chef 和 Puppet）。这些工具在自动执行任务和提供一致性方面有很大帮助，但是它们在提供必要的抽象来描述超出单个服务器的基础设施方面存在缺陷。&lt;/p&gt;
&lt;p&gt;配置管理工具一次自动化一台服务器，并依靠人员将服务器提供的功能绑定在一起。这将人类定位为基础设施规模的潜在瓶颈。这些工具也不会使构建完整系统所需的云基础设施（例如存储和网络）的额外部分自动化。&lt;/p&gt;
&lt;p&gt;尽管配置管理工具为操作系统的资源（例如软件包管理器）提供了一些抽象，但它们并没有抽象出足够的底层操作系统来轻松管理它。如果一位工程师想要管理系统中的每个软件包和文件，这将是一个非常艰苦的过程，并且对于每个配置变体都是独一无二的。同样，定义不存在或不正确的资源的配置管理仅消耗系统资源并且不能提供任何价值。&lt;/p&gt;
&lt;p&gt;虽然配置管理工具可以帮助自动化部分基础设施，但它们无法更好地管理应用程序。我们将在后面的章节中通过查看部署，管理，测试和操作基础架构的流程，探讨云原生基础设施的不同之处，但首先，我们将了解哪些应用程序是成功的以及应该何时与原生基础设施一起使用。&lt;/p&gt;
&lt;h2 id=&#34;云原生应用程序&#34;&gt;云原生应用程序&lt;/h2&gt;
&lt;p&gt;就像云改变了业务和基础设施之间的关系一样，云原生应用程序也改变了应用程序和基础设施之间的关系。我们需要了解与传统应用程序相比，云本身有什么不同，因此我们需要了解它们与基础设施的新关系。&lt;/p&gt;
&lt;p&gt;为了写好本书，也为了有一个共享词汇表，我们需要定义 “云原生应用程序” 是什么意思。云原生与 12 因素应用程序不同，即使它们可能共享一些类似的特征。如果你想了解更多细节，请阅读 Kevin Hoffman 撰写的 “超越 12 因素应用程序”（O&amp;rsquo;Reilly，2012）。&lt;/p&gt;
&lt;p&gt;云原生应用程序被设计为在平台上运行，并设计用于弹性，敏捷性，可操作性和可观察性。弹性包含失败而不是试图阻止它们；它利用了在平台上运行的动态特性。敏捷性允许快速部署和快速迭代。可操作性从应用程序内部控制应用程序生命周期，而不是依赖外部进程和监视器。可观察性提供信息来回答有关应用程序状态的问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;云原生定义&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;云原生应用程序的定义仍在发展中。还有像 CNCF 这样的组织可以提供其他的定义。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;云原生应用程序通过各种方法获取这些特征。它通常取决于应用程序的运行位置以及企业流程和文化。以下是实现云原生应用程序所需特性的常用方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微服务&lt;/li&gt;
&lt;li&gt;健康报告&lt;/li&gt;
&lt;li&gt;遥测数据&lt;/li&gt;
&lt;li&gt;弹性&lt;/li&gt;
&lt;li&gt;声明式的，而不是命令式的&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;微服务&#34;&gt;微服务&lt;/h3&gt;
&lt;p&gt;作为单个实体进行管理和部署的应用程序通常称为单体应用。最初开发应用程序时，单体有很多好处。它们更易于理解，并允许您在不影响其他服务的情况下更改主要功能。&lt;/p&gt;
&lt;p&gt;随着应用程序复杂性的增长，单体应用的益处逐渐减少。它们变得更难理解，而且失去了敏捷性，因为工程师很难推断和修改代码。&lt;/p&gt;
&lt;p&gt;对付复杂性的最好方法之一是将明确定义的功能分成更小的服务，并让每个服务独立迭代。这增加了应用程序的灵活性，允许根据需要更轻松地更改部分应用程序。每个微服务可以由单独的团队进行管理，使用适当的语言编写，并根据需要进行独立扩缩容。&lt;/p&gt;
&lt;p&gt;只要每项服务都遵守强有力的合约，应用程序就可以快速改进和改变。当然，转向微服务架构还有许多其他的考虑因素。其中最不重要的是弹性通信，我们在附录 A 中有讨论。&lt;/p&gt;
&lt;p&gt;我们无法考虑转向微服务的所有考虑因素。拥有微服务并不意味着您拥有云原生基础设施。如果您想阅读更多，我们推荐 Sam Newman 的 Building Microservices（O&amp;rsquo;Reilly，2015）。虽然微服务是实现您的应用程序灵活性的一种方式，但正如我们之前所说的，它们不是云原生应用程序的必需条件。&lt;/p&gt;
&lt;h3 id=&#34;健康报告&#34;&gt;健康报告&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;停止逆向工程应用程序并开始从内部进行监控。 —— Kelsey Hightower，Monitorama PDX 2016：healthz&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;没有人比开发人员更了解应用程序需要什么才能以健康的状态运行。很长一段时间，基础设施管理员都试图从他们负责运行的应用程序中找出 “健康” 该怎么定义。如果不实际了解应用程序的健康状况，他们尝试在应用程序不健康时进行监控并发出警报，这往往是脆弱和不完整的。&lt;/p&gt;
&lt;p&gt;为了提高云原生应用程序的可操作性，应用程序应该暴露健康检查。开发人员可以将其实施为命令或过程信号，以便应用程序在执行自我检查之后响应，或者更常见的是：通过应用程序提供 Web 服务，返回 HTTP 状态码来检查健康状态。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Google Borg 示例&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Google 的 Borg 报告中列出了一个健康报告的例子：&lt;/p&gt;
&lt;p&gt;几乎每个在 Borg 下运行的任务都包含一个内置的 HTTP 服务器，该服务器发布有关任务运行状况和数千个性能指标（如 RPC 延迟）的信息。Borg 会监控运行状况检查 URL 并重新启动不及时响应或返回 HTTP 错误代码的任务。其他数据由监控工具跟踪，用于仪表板和服务级别目标（SLO）违规警报。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;将健康责任转移到应用程序中使应用程序更容易管理和自动化。应用程序应该知道它是否正常运行以及它依赖于什么（例如，访问数据库）来提供业务价值。这意味着开发人员需要与产品经理合作来定义应用服务的业务功能并相应地编写测试。&lt;/p&gt;
&lt;p&gt;提供健康检查的应用程序示例包括 Zookeeper 的 ruok 命令和 etcd 的 HTTP / 健康端点。&lt;/p&gt;
&lt;p&gt;应用程序不仅仅有健康或不健康的状态。它们将经历一个启动和关闭过程，在这个过程中它们应该通过健康检查，报告它们的状态。如果应用程序可以让平台准确了解它所处的状态，平台将更容易知道如何操作它。&lt;/p&gt;
&lt;p&gt;一个很好的例子就是当平台需要知道应用程序何时可以接收流量。在应用程序启动时，如果它不能正确处理流量，它就应该表现为未准备好。此额外状态将防止应用程序过早终止，因为如果运行状况检查失败，平台可能会认为应用程序不健康，并且会反复停止或重新启动它。&lt;/p&gt;
&lt;p&gt;应用程序健康只是能够自动化应用程序生命周期的一部分。除了知道应用程序是否健康之外，您还需要知道应用程序是否正在进行哪些工作。这些信息来自遥测数据。&lt;/p&gt;
&lt;h3 id=&#34;遥测数据&#34;&gt;遥测数据&lt;/h3&gt;
&lt;p&gt;遥测数据是进行决策所需的信息。确实，遥测数据可能与健康报告重叠，但它们有不同的用途。健康报告通知我们应用程序生命周期状态，而遥测数据通知我们应用程序业务目标。&lt;/p&gt;
&lt;p&gt;您测量的指标有时称为服务级指标（SLI）或关键性能指标（KPI）。这些是特定于应用程序的数据，可以确保应用程序的性能处于服务级别目标（SLO）内。如果您需要更多关于这些术语的信息以及它们与您的应用程序、业务需求的关系，我们推荐你阅读来自 Site Reliability Engineering（O&amp;rsquo;Reilly）的第 4 章。&lt;/p&gt;
&lt;p&gt;遥测和度量标准用于解决以下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用程序每分钟收到多少请求？&lt;/li&gt;
&lt;li&gt;有没有错误？&lt;/li&gt;
&lt;li&gt;什么是应用程序延迟？&lt;/li&gt;
&lt;li&gt;订购需要多长时间？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通常会将数据刮取或推送到时间序列数据库（例如 Prometheus 或 InfluxDB）进行聚合。遥测数据的唯一要求是它将被收集数据的系统格式化。&lt;/p&gt;
&lt;p&gt;至少，可能最好实施度量标准的 RED 方法，该方法收集应用程序的速率，错误和执行时间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;请求率&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;收到了多少个请求&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;错误&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;应用程序有多少错误&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;时间&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;多久才能收到回复&lt;/p&gt;
&lt;p&gt;遥测数据应该用于提醒而非健康监测。在动态的、自我修复的环境中，我们更少关注单个应用程序实例的生命周期，更多关注关于整体应用程序 SLO 的内容。健康报告对于自动应用程序管理仍然很重要，但不应该用于页面工程师。&lt;/p&gt;
&lt;p&gt;如果 1 个实例或 50 个应用程序不健康，只要满足应用程序的业务需求，我们可能不会收到警报。度量标准可让您知道您是否符合您的 SLO，应用程序的使用方式以及对于您的应用程序来说什么是 “正常”。警报有助于您将系统恢复到已知的良好状态。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果它移动，我们跟踪它。有时候我们会画出一些尚未移动的图形，以防万一它决定为它运行。&lt;/p&gt;
&lt;p&gt;——Ian Malpass，衡量所有，衡量一切&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;警报也不应该与日志记录混淆。记录用于调试，开发和观察模式。它暴露了应用程序的内部功能。度量有时可以从日志（例如错误率）计算，但需要额外的聚合服务（例如 ElasticSearch）和处理。&lt;/p&gt;
&lt;h3 id=&#34;弹性&#34;&gt;弹性&lt;/h3&gt;
&lt;p&gt;一旦你有遥测和监测数据，你需要确保你的应用程序对故障有适应能力。弹性是基础设施的责任，但云原生应用程序也需要承担部分工作。&lt;/p&gt;
&lt;p&gt;基础设施被设计为抵制失败。硬件用于需要多个硬盘驱动器，电源以及全天候监控和部件更换以保持应用程序可用。使用云原生应用程序，应用程序有责任接受失败而不是避免失败。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在任何平台上，尤其是在云中，最重要的特性是其可靠性。&lt;/p&gt;
&lt;p&gt;——David Rensin，e ARCHITECT Show：来自 Google 的关于云计算的速成课程&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;设计具有弹性的应用程序可能是整本书本身。我们将在云原生应用程序中考虑弹性的两个主要方面：为失败设计和优雅降级。&lt;/p&gt;
&lt;h4 id=&#34;为失败设计&#34;&gt;为失败设计&lt;/h4&gt;
&lt;p&gt;唯一永远不会失败的系统是那些让你活着的系统（例如心脏植入物和刹车系统）。如果您的服务永远不会停止运行，您需要花费太多时间设计它们来抵制故障，并且没有足够的时间增加业务价值。您的 SLO 确定服务需要多长时间。您花费在工程设计上超出 SLO 的正常运行时间的任何资源都将被浪费掉。&lt;/p&gt;
&lt;p&gt;您应该为每项服务测量两个值，即平均无故障时间（MTBF）和平均恢复时间（MTTR）。监控和指标可以让您检测您是否符合您的 SLO，但运行应用程序的平台是保持高 MTBF 和低 MTTR 的关键。&lt;/p&gt;
&lt;p&gt;在任何复杂的系统中，都会有失败。您可以管理硬件中的某些故障（例如，RAID 和冗余电源），以及某些基础设施中的故障（例如负载平衡器）。但是因为应用程序知道他们什么时候健康，所以他们也应该尽可能地管理自己的失败。&lt;/p&gt;
&lt;p&gt;设计一个以失败期望为目标的应用程序将比假定可用性的应用程序更具防御性。当故障不可避免时，将会有额外的检查，故障模式和日志内置到应用程序中。&lt;/p&gt;
&lt;p&gt;知道应用程序可能失败的每种方式是不可能的。假设任何事情都可能并且可能会失败，这是一种云原生应用程序的模式。&lt;/p&gt;
&lt;p&gt;您的应用程序的最佳状态是健康状态。第二好的状态是失败状态。其他一切都是非二进制的，难以监控和排除故障。 Honeycomb 首席执行官 CharityMajors 在她的文章 “Ops：现在每个人都在工作” 中指出：“分布式系统永远不会起作用；它们处于部分退化服务的持续状态。接受失败，设计弹性，保护和缩小关键路径。”&lt;/p&gt;
&lt;p&gt;无论发生什么故障，云原生应用程序都应该是可适应的。他们期望失败，所以他们在检测到时进行调整。&lt;/p&gt;
&lt;p&gt;有些故障不能也不应该被设计到应用程序中（例如，网络分区和可用区故障）。该平台应自主处理未集成到应用程序中的故障域。&lt;/p&gt;
&lt;h4 id=&#34;优雅降级&#34;&gt;优雅降级&lt;/h4&gt;
&lt;p&gt;云原生应用程序需要有一种方法来处理过载，无论它是应用程序还是负载下的相关服务。处理负载的一种方式是优雅降级。 “站点可靠性工程” 一书中描述了应用程序的优雅降级，因为它提供的响应在负载过重的情况下 “不如正常响应准确或含有较少数据的响应，但计算更容易”。&lt;/p&gt;
&lt;p&gt;减少应用程序负载的某些方面由基础设施处理。智能负载平衡和动态扩展可以提供帮助，但是在某些时候，您的应用程序可能承受的负载比它可以处理的负载更多。云原生应用程序需要知道这种必然性并作出相应的反应。&lt;/p&gt;
&lt;p&gt;优雅降级的重点是允许应用程序始终返回请求的答案。如果应用程序没有足够的本地计算资源，并且依赖服务没有及时返回信息，则这是正确的。依赖于一个或多个其他服务的服务应该可用于应答请求，即使依赖于服务不是。当服务退化时，返回部分答案或使用本地缓存中的旧信息进行答案是可能的解决方案。&lt;/p&gt;
&lt;p&gt;尽管优雅的降级和失败处理都应该在应用程序中实现，但平台的多个层面应该提供帮助。如果采用微服务，则网络基础设施成为需要在提供应用弹性方面发挥积极作用的关键组件。有关构建弹性网络层的更多信息，请参阅附录 A。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;可用性数学&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;云原生应用程序需要在基础设施之上建立一个平台，以使基础设施更具弹性。如果您希望将现有应用程序 “提升并转移” 到云中，则应检查云提供商的服务级别协议（SLA），并考虑在使用多个服务时会发生什么情况。&lt;/p&gt;
&lt;p&gt;让我们拿运行我们的应用程序的云来进行假设。&lt;/p&gt;
&lt;p&gt;计算基础设施的典型可用性是每月 99.95％的正常运行时间。这意味着您的实例每天可能会缩短到 43.2 秒，并且仍在您的云服务提供商的 SLA 中。&lt;/p&gt;
&lt;p&gt;另外，实例的本地存储（例如 EBS 卷）也具有 99.95％的可用性正常运行时间。如果幸运的话，他们都会同时出现故障，但最糟糕的情况是他们可能会在不同的时间停机，让您的实例只有 99.9％的可用性。&lt;/p&gt;
&lt;p&gt;您的应用程序可能还需要一个数据库，而不是自己安装一个计算可能的停机时间为 1 分 26 秒（99.9％可用性）的情况下，选择可靠性为 99.95％的更可靠的托管数据库。这使您的应用程序的可靠性达到 99.85％，或者每天可能发生 2 分钟和 9 秒的宕机时间。&lt;/p&gt;
&lt;p&gt;将可用性乘到一起可以快速了解为什么应以不同方式处理云。真正不好的部分是，如果云提供商不符合其 SLA，它将退还其账单中一定比例的退款。&lt;/p&gt;
&lt;p&gt;虽然您不必为停机支付费用，但我们并不知道世界上存在云计算信用的单一业务。如果您的应用程序的可用性不足以超过您收到的信用额度，那么您应该真正考虑是否应该运行这个应用程序。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;声明式非反应式&#34;&gt;声明式，非反应式&lt;/h3&gt;
&lt;p&gt;因为云原生应用程序被设计为在云环境中运行，所以它们与基础设施以及相关依赖应用程序的交互方式不同于传统应用程序。在云原生应用程序中，与任何事物的通信都需要通过网络来进行。很多时候，网络通信是通过 RESTful HTTP 调用完成的，但是也可以通过其他接口实现，比如远程过程调用 (RPC)。&lt;/p&gt;
&lt;p&gt;传统的应用程序会通过向消息队列发送消息、在共享存储上写入文件或触发本地 shell 脚本来执行自动化任务。通信方法基于发生的事件作出反应（例如，如果用户单击提交，运行提交脚本）并且通常需要存在于同一物理或虚拟服务器上的信息。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Serverless&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;无服务器平台是云原生化的，并被设计为对事件做出反应。他们在云中工作得很好的原因是他们通过 HTTP API 进行通信，（这些 API）是单一用途的函数，并且在它们的调用中是声明性的。该平台还使它们可伸缩并可从云内访问。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;传统应用程序中的反应式通信通常是构建弹性的一种尝试。如果应用程序（以反应式的方式）在磁盘上或消息队列中写入了一个文件，然后应用程序死亡，那么该消息或文件的结果仍然可以完成。&lt;/p&gt;
&lt;p&gt;这里并不是说不应该使用像消息队列这样的技术，而是说在动态且经常出现故障的系统中，不能将它们作为惟一的弹性层来依赖。从根本上说，在云原生环境之中，应用程序之间的通信方法应该有所变化 - 这不仅是因为还存在其他方法来构建通信弹性（请参阅附录 A），而且还因为如果要让传统的通信方法在云中实现复制，我们往往需要做更多工作。&lt;/p&gt;
&lt;p&gt;当应用程序可以信任通信的弹性时，它们应该放弃反应式并使用声明式。声明式通信信任网络会将消息送达。它也相信应用程序将返回成功或错误。这并不是说让应用程序观察变化不重要。Kubernetes 的控制器对 API 服务器做的就是这个。但是，一旦发现变更，他们就会声明一个新的状态，并相信 API 服务器和 kubelets 会做必要的事情。&lt;/p&gt;
&lt;p&gt;声明式通信模型由于多种原因而变得更加健壮。最重要的是，它规范了通信模型，并且它将（如何从某种状态到达期望状态的）功能实现从应用程序转移到远程 API 或服务端点。这有助于简化应用程序，并使它们彼此的行为更具可预测性。&lt;/p&gt;
&lt;h3 id=&#34;云原生应用程序如何影响基础设施&#34;&gt;云原生应用程序如何影响基础设施？&lt;/h3&gt;
&lt;p&gt;希望你可以知道云原生应用程序与传统应用程序不同。云原生应用程序不能直接在 PaaS 上运行或与服务器的操作系统紧密耦合。它们期望在一个拥有大多数自治系统的动态环境中运行。&lt;/p&gt;
&lt;p&gt;云原生基础设施在提供自主应用管理的 IaaS 之上创建了一个平台。该平台建立在动态创建的基础设施之上，以抽象出单个服务器并促进动态资源分配调度。&lt;/p&gt;
&lt;p&gt;自动化与自治不一样。自动化使人类对他们所采取的行动产生更大的影响。&lt;/p&gt;
&lt;p&gt;云原生是关于不需要人类做出决定的自治系统。它仍然使用自动化，但只有在决定了所需的操作之后。只有在系统不能自动确定正确的事情时才应该通知人。&lt;/p&gt;
&lt;p&gt;具有这些特征的应用程序需要一个能够实际监控，收集度量标准并在发生故障时做出反应的平台。云原生应用程序不依赖于人员设置 ping 检查或创建 Syslog 规则。他们需要从选择基本操作系统或软件包管理器的过程中提取自助服务资源，并依靠服务发现和强大的网络通信来提供丰富的功能体验。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.heptio.com/i-still-remember-the-first-time-i-logged-into-a-production-server-over-ssh-and-telling-myself-i-53ab1d1e7f46&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;“Cloud Native Infrastructure”, a Free O’Reilly eBook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>什么是云原生应用？</title>
      <link>https://jimmysong.io/docs/cloud-native/intro/define-cloud-native-app/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0100</pubDate>
      <guid>https://jimmysong.io/docs/cloud-native/intro/define-cloud-native-app/</guid>
      <description>&lt;p&gt;本文参考的是 &lt;a href=&#34;https://github.com/oam-dev/spec&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OAM 规范&lt;/a&gt;中对云原生应用的定义，并做出了引申。&lt;/p&gt;
&lt;p&gt;云原生应用是一个相互关联但又不独立的组件（service、task、worker）的集合，这些组件与配置结合在一起并在适当的运行时实例化后，共同完成统一的功能目的。&lt;/p&gt;
&lt;h2 id=&#34;云原生应用模型&#34;&gt;云原生应用模型&lt;/h2&gt;
&lt;p&gt;下图是 OAM 定义的云原生应用模型示意图，为了便于理解，图中相同颜色的部分为同一类别的对象定义。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/cloud-native-app-model.png&#34; alt=&#34;云原生应用模型&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;OAM 的规范中定义了以下对象，它们既是 OAM 规范中的基本术语也是云原生应用的基本组成。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Workload（工作负载）&lt;/strong&gt;：应用程序的工作负载类型，由平台提供。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Component组件）&lt;/strong&gt;：定义了一个 &lt;code&gt;Workload&lt;/code&gt; 的实例，并以基础设施中立的术语声明其运维特性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Trait（特征）&lt;/strong&gt;：用于将运维特性分配给组件实例。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ApplicationScope（应用作用域）&lt;/strong&gt;：用于将组件分组成具有共同特性的松散耦合的应用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ApplicationConfiguration（应用配置）&lt;/strong&gt;：描述 &lt;code&gt;Component&lt;/code&gt; 的部署、&lt;code&gt;Trait&lt;/code&gt; 和 &lt;code&gt;ApplicationScope&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OAM 规范中提供了一个使用以上对象定义云原生应用的&lt;a href=&#34;https://github.com/oam-dev/spec/blob/master/examples/workflow.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;工作流示例&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;关注点分离&#34;&gt;关注点分离&lt;/h2&gt;
&lt;p&gt;下图是不同角色对于该模型的关注点示意图。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/roles.png&#34; alt=&#34;云原生应用模型中的目标角色&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们可以看到对于一个云原生应用来说，不同的对象是由不同的角色来负责的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基础设施运维：提供不同的 &lt;code&gt;Workload&lt;/code&gt; 类型供开发者使用；&lt;/li&gt;
&lt;li&gt;应用运维：定义适用于不同 &lt;code&gt;Workload&lt;/code&gt; 的运维属性 &lt;code&gt;Trait&lt;/code&gt; 和管理 &lt;code&gt;Component&lt;/code&gt; 的 &lt;code&gt;ApplicationScope&lt;/code&gt; 即作用域；&lt;/li&gt;
&lt;li&gt;应用开发者：负责应用组件 &lt;code&gt;Component&lt;/code&gt; 的定义；&lt;/li&gt;
&lt;li&gt;应用开发者和运维：共同将 &lt;code&gt;Component&lt;/code&gt; 与运维属性 &lt;code&gt;Trait&lt;/code&gt; 绑定在一起，维护应用程序的生命周期；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基于 OAM 中的对象定义的云原生应用可以充分利用平台能力自由组合，开发者和运维人员的职责可以得到有效分离，组件的复用性得到大幅提高。&lt;/p&gt;
&lt;h2 id=&#34;定义标准&#34;&gt;定义标准&lt;/h2&gt;
&lt;p&gt;CNCF 中的有几个定义标准的「开源项目」，其中有的项目都已经毕业。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/servicemeshinterface/smi-spec&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SMI（Service Mesh Interface）&lt;/a&gt;：服务网格接口&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudevents/spec&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Events&lt;/a&gt;：Serverless 中的事件标准&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/theupdateframework/specification&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TUF&lt;/a&gt;：更新框架标准&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spiffe/spiffe&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SPIFFE&lt;/a&gt;：身份安全标准&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这其中唯独没有应用定义标准，&lt;a href=&#34;https://github.com/cncf/sig-app-delivery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF SIG App delivery&lt;/a&gt; 即是要做这个的。当然既然要指定标准，自然要对不同平台和场景的逻辑做出更高级别的抽象（这也意味着你在掌握了底层逻辑的情况下还要学习更多的概念），这样才能屏蔽底层差异。&lt;/p&gt;
&lt;h2 id=&#34;oam-简介&#34;&gt;OAM 简介&lt;/h2&gt;
&lt;p&gt;OAM 全称是 Open Application Model，从名称上来看它所定义的就是一种模型，同时也实现了基于 OAM 的我认为这种模型旨在定义了云原生应用的标准。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;开放（Open）：支持异构的平台、容器运行时、调度系统、云供应商、硬件配置等，总之与底层无关&lt;/li&gt;
&lt;li&gt;应用（Application）：云原生应用&lt;/li&gt;
&lt;li&gt;模型（Model）：定义标准，以使其与底层平台无关&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;既然要制定标准，自然要对不同平台和场景的逻辑做出更高级别的抽象（这也意味着你在掌握了底层逻辑的情况下还要学习更多的概念），这样才能屏蔽底层差异。本文将默认底层平台为 Kubernetes。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;是从管理大量 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/GLOSSARY.html#crd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRD&lt;/a&gt; 中汲取的经验。&lt;/li&gt;
&lt;li&gt;业务和研发的沟通成本，比如 YAML 配置中很多字段是开发人员不关心的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;设计原则&#34;&gt;设计原则&lt;/h2&gt;
&lt;p&gt;OAM 规范的设计遵循了以下&lt;a href=&#34;https://github.com/oam-dev/spec/blob/master/9.design_principles.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原则&lt;/a&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;关注点分离：根据功能和行为来定义模型，以此划分不同角色的职责，&lt;/li&gt;
&lt;li&gt;平台中立：OAM 的实现不绑定到特定平台；&lt;/li&gt;
&lt;li&gt;优雅：尽量减少设计复杂性；&lt;/li&gt;
&lt;li&gt;复用性：可移植性好，同一个应用程序可以在不同的平台上不加改动地执行；&lt;/li&gt;
&lt;li&gt;不作为编程模型：OAM 提供的是应用程序模型，描述了应用程序的组成和组件的拓扑结构，而不关注应用程序的具体实现。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图是 OAM 规范示意图。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/oam-spec.png&#34; alt=&#34;OAM 规范示意图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;oam-工作原理&#34;&gt;OAM 工作原理&lt;/h2&gt;
&lt;p&gt;OAM 的工作原理如下图所示（图片引用自孙健波在《OAM: 云原生时代的应用模型与 下一代 DevOps 技术》中的分享）。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/oam-principle.jpg&#34; alt=&#34;OAM 的原理&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;OAM Spec 定义了云原生应用的规范（使用一些 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/GLOSSARY.html#crd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRD&lt;/a&gt; 定义）， &lt;a href=&#34;https://kubevela.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KubeVela&lt;/a&gt; 可以看做是 OAM 规范的解析器，将应用定义翻译为 Kubernetes 中的资源对象。可以将上图分为三个层次：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;汇编层&lt;/strong&gt;：即人工或者使用工具来根据 OAM 规范定义汇编出一个云原生应用的定义，其中包含了该应用的工作负载和运维能力配置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;转义层&lt;/strong&gt;：汇编好的文件将打包为 YAML 文件，由 &lt;a href=&#34;https://kubevela.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KubeVela&lt;/a&gt; 或其他 OAM 的实现将其转义为 Kubernetes 或其他云服务（例如 Istio）上可运行的资源对象。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;执行层&lt;/strong&gt;：执行经过转义好的云平台上的资源对象并执行资源配置。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/oam-dev/spec&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Open Application Model specification - github.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>云原生快速入门</title>
      <link>https://jimmysong.io/docs/cloud-native/intro/quick-start/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0100</pubDate>
      <guid>https://jimmysong.io/docs/cloud-native/intro/quick-start/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes&lt;/a&gt; 一词来自希腊语，意思是 “飞行员” 或 “舵手”。这个名字很贴切，Kubernetes 可以帮助你在波涛汹涌的容器海洋中航行。&lt;/p&gt;
&lt;p&gt;Kubernetes 是做什么的？什么是 Docker？什么是容器编排？Kubernetes 是如何工作和扩展的？你可能还有很多其他的问题，本文将一一为你解答。&lt;/p&gt;
&lt;p&gt;这篇文章适合初学者，尤其是那些工作忙碌，没有办法抽出太多时间来了解 Kubernetes 和云原生的开发者们，希望本文可以帮助你进入 Kubernetes 的世界。&lt;/p&gt;
&lt;p&gt;简而言之，Kubernetes 提供了一个平台或工具来帮助你快速协调或扩展容器化应用，特别是在 &lt;a href=&#34;https://docker.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker&lt;/a&gt; 容器。让我们深入了解一下这些概念。&lt;/p&gt;
&lt;h2 id=&#34;容器和容器化&#34;&gt;容器和容器化&lt;/h2&gt;
&lt;p&gt;那么什么是容器呢？&lt;/p&gt;
&lt;p&gt;要讨论容器化首先要谈到虚拟机 (VM)，顾名思义，虚拟机就是可以远程连接的虚拟服务器，比如 AWS 的 EC2 或阿里云的 ECS。&lt;/p&gt;
&lt;p&gt;接下来，假如你要在虚拟机上运行一个网络应用 —— 包括一个 MySQL 数据库、一个 Vue 前端和一些 Java 库，在 Ubuntu 操作系统 (OS) 上运行。你不用熟悉其中的每一个技术 —— 你只要记住，一个应用程序由各种组件、服务和库组成，它们运行在操作系统上。&lt;/p&gt;
&lt;p&gt;现在，将应用程序打包成一个虚拟机镜像，这个镜像中包括了 Ubuntu 操作系统。这使得虚拟机变得非常笨重 —— 通常有几个 G 的大小。&lt;/p&gt;
&lt;p&gt;虚拟机镜像包含了整个操作系统及所有的库，对应用程序来说，这个镜像过于臃肿，其中大部分组件并没有被应用程序直接调用。如果你需要重新创建、备份或扩展这个应用程序，就需要复制整个环境（虚拟机镜像），在新环境中启动应用通常需要几十秒甚至几分钟时间。如果你想单独升级应用中的某个组件，比如说 Vue 应用，就需要重建整个虚拟机镜像。另外，如果你的两个应用依赖同一个底层镜像，升级底层镜像会同时影响这两个应用，而有时候，你只需要升级其中一个应用的依赖而已。这就是所谓的 “依赖陷阱”。&lt;/p&gt;
&lt;p&gt;解决这个问题的办法就是容器。容器是继虚拟机之后更高层次的抽象，在这层抽象中，整个应用程序的每个组件被单独打包成一个个独立的单元，这个单元就是所谓的容器。通过这种方式，可以将代码和应用服务从底层架构中分离出来，实现了完全的可移植性（在任何操作系统或环境上运行应用的能力）。所以在上面的例子中，Ubuntu 操作系统就是一个单元（容器）。MySQL 数据库是另一个容器，Vue 环境和随之而来的库也是一个容器。&lt;/p&gt;
&lt;p&gt;但是，MySQL 数据库是如何自己 “运行” 的？数据库本身肯定也要在操作系统上运行吧？没错！&lt;/p&gt;
&lt;p&gt;更高层次的容器，比如 MySQL 容器，实际上会包含必要的库来与底层的操作系统容器通信和集成。所以你可以把容器看成是整个应用堆栈中的一层，每层都依赖于下层的单元。而这就类似于船舶或港口中集装箱的堆叠方式，每个容器的稳定性都依赖于下面的容器的支持。所以应用容器的核心是一个受控的执行环境。它们允许你从头开始定义整个环境，从操作系统开始，到你要使用的各个版本的库，再到你要添加的代码版本。&lt;/p&gt;
&lt;p&gt;与容器相关的一个重要概念是&lt;strong&gt;微服务&lt;/strong&gt;。将应用程序的各个组件拆分并打包成独立的服务，这样每个组件都可以很容易地被替换、升级、调试。上面的例子中，我们会为 Vue 前端创建一个微服务，为 MySQL 数据库创建另一个微服务，为 Java 中间件部分创建另一个微服务，以此类推。很明显，微服务与容器化是相辅相成的。&lt;/p&gt;
&lt;h2 id=&#34;从-docker-开始&#34;&gt;从 Docker 开始&lt;/h2&gt;
&lt;p&gt;现在你已经对容器有一定了解了吧？Docker 是最常用的容器化工具，也是最流行的容器运行时。&lt;/p&gt;
&lt;p&gt;Docker 开源于 2013 年。用于打包和创建容器，管理基于容器的应用。所有 Linux 发行版、Windows 和 macOS 都支持 Docker。&lt;/p&gt;
&lt;p&gt;还有其他的容器化工具，如 &lt;a href=&#34;https://coreos.com/rkt/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CoreOS rkt&lt;/a&gt;、&lt;a href=&#34;https://mesos.apache.org/documentation/latest/mesos-containerizer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mesos Containerizer&lt;/a&gt; 和 &lt;a href=&#34;https://linuxcontainers.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LXC&lt;/a&gt;。但是目前，绝大多数的容器化应用都是在 Docker 上运行的。&lt;/p&gt;
&lt;h2 id=&#34;再到-kubernetes&#34;&gt;再到 Kubernetes&lt;/h2&gt;
&lt;p&gt;首先，简单介绍一下历史。Kubernetes 是 Google 基于其内部容器调度平台 Borg 的经验开发的。2014 年开源，并作为 CNCF（云原生计算基金会）的核心发起项目。&lt;/p&gt;
&lt;p&gt;那么 Kubernetes 又跟容器是什么关系呢？让我们再回到上面的例子。假设我们的应用爆火，每天的注册用户越来越多。&lt;/p&gt;
&lt;p&gt;现在，我们需要增加后端资源，使浏览我们网站的用户在浏览页面时加载时间不会过长或者超时。最简单的方式就是增加容器的数量，然后使用负载均衡器将传入的负载（以用户请求的形式）分配给容器。&lt;/p&gt;
&lt;p&gt;这样做虽然行之有效，但也只能在用户规模有限的情况下使用。当用户请求达到几十万或几百万时，这种方法也是不可扩展的。你需要管理几十个也许是几百个负载均衡器，这本身就是另一个令人头疼的问题。如果我们想对网站或应用进行任何升级，也会遇到问题，因为负载均衡不会考虑到应用升级的问题。我们需要单独配置每个负载均衡器，然后升级该均衡器所服务的容器。想象一下，当你有 20 个负载均衡器和每周 5 或 6 个小的更新时，你将不得不进行大量的手工劳动。&lt;/p&gt;
&lt;p&gt;我们需要的是一种可以一次性将变更传递给所有受控容器的方法，同时也需要一种可以轻松地调度可用容器的方法，这个过程还必须要是自动化的，这正是 Kubernetes 所做的事情。&lt;/p&gt;
&lt;p&gt;接下来，我们将探讨 Kubernetes 究竟是如何工作的，它的各种组件和服务，以及更多关于如何使用 Kubernetes 来编排、管理和监控容器化环境。为了简单起见，假设我们使用的是 Docker 容器，尽管如前所述，Kubernetes 除了支持 Docker 之外，还支持其他几种容器平台。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-架构和组件&#34;&gt;Kubernetes 架构和组件&lt;/h2&gt;
&lt;p&gt;首先，最重要的是你需要认识到 Kubernetes 利用了 “期望状态” 原则。就是说，你定义了组件的期望状态，而 Kubernetes 要将它们始终调整到这个状态。&lt;/p&gt;
&lt;p&gt;例如，你想让你的 Web 服务器始终运行在 4 个容器中，以达到负载均衡的目的，你的数据库复制到 3 个不同的容器中，以达到冗余的目的。这就是你想要的状态。如果这 7 个容器中的任何一个出现故障，Kubernetes 引擎会检测到这一点，并自动创建出一个新的容器，以确保维持所需的状态。&lt;/p&gt;
&lt;p&gt;现在我们来定义一些 Kubernetes 的重要组件。&lt;/p&gt;
&lt;p&gt;当你第一次设置 Kubernetes 时，你会创建一个集群。所有其他组件都是集群的一部分。你也可以创建多个虚拟集群，称为命名空间 (namespace)，它们是同一个物理集群的一部分。这与你可以在同一物理服务器上创建多个虚拟机的方式非常相似。如果你不需要，也没有明确定义的命名空间，那么你的集群将在始终存在的默认命名空间中创建。&lt;/p&gt;
&lt;p&gt;Kubernetes 运行在节点 (node) 上，节点是集群中的单个机器。如果你有自己的硬件，节点可能对应于物理机器，但更可能对应于在云中运行的虚拟机。节点是部署你的应用或服务的地方，是 Kubernetes 工作的地方。有 2 种类型的节点 ——master 节点和 worker 节点，所以说 Kubernetes 是主从结构的。&lt;/p&gt;
&lt;p&gt;主节点是一个控制其他所有节点的特殊节点。一方面，它和集群中的任何其他节点一样，这意味着它只是另一台机器或虚拟机。另一方面，它运行着控制集群其他部分的软件。它向集群中的所有其他节点发送消息，将工作分配给它们，工作节点向主节点上的 API Server 汇报。&lt;/p&gt;
&lt;p&gt;Master 节点本身也包含一个名为 API Server 的组件。这个 API 是节点与控制平面通信的唯一端点。API Server 至关重要，因为这是 worker 节点和 master 节点就 pod、deployment 和所有其他 Kubernetes API 对象的状态进行通信的点。&lt;/p&gt;
&lt;p&gt;Worker 节点是 Kubernetes 中真正干活的节点。当你在应用中部署容器或 pod（稍后定义）时，其实是在将它们部署到 worker 节点上运行。Worker 节点托管和运行一个或多个容器的资源。&lt;/p&gt;
&lt;p&gt;Kubernetes 中的逻辑而非物理的工作单位称为 pod。一个 pod 类似于 Docker 中的容器。记得我们在前面讲到，容器可以让你创建独立、隔离的工作单元，可以独立运行。但是要创建复杂的应用程序，比如 Web 服务器，你经常需要结合多个容器，然后在一个 pod 中一起运行和管理。这就是 pod 的设计目的 —— 一个 pod 允许你把多个容器，并指定它们如何组合在一起来创建应用程序。而这也进一步明确了 Docker 和 Kubernetes 之间的关系 —— 一个 Kubernetes pod 通常包含一个或多个 Docker 容器，所有的容器都作为一个单元来管理。&lt;/p&gt;
&lt;p&gt;Kubernetes 中的 service 是一组逻辑上的 pod。把一个 service 看成是一个 pod 的逻辑分组，它提供了一个单一的 IP 地址和 DNS 名称，你可以通过它访问服务内的所有 pod。有了服务，就可以非常容易地设置和管理负载均衡，当你需要扩展 Kubernetes pod 时，这对你有很大的帮助，我们很快就会看到。&lt;/p&gt;
&lt;p&gt;ReplicationController 或 ReplicaSet 是 Kubernetes 的另一个关键功能。它是负责实际管理 pod 生命周期的组件 —— 当收到指令时或 pod 离线或意外停止时启动 pod，也会在收到指示时杀死 pod，也许是因为用户负载减少。所以换句话说，ReplicationController 有助于实现我们所期望的指定运行的 pod 数量的状态。&lt;/p&gt;
&lt;h2 id=&#34;什么是-kubectl&#34;&gt;什么是 Kubectl？&lt;/h2&gt;
&lt;p&gt;kubectl 是一个命令行工具，用于与 Kubernetes 集群和其中的 pod 通信。使用它你可以查看集群的状态，列出集群中的所有 pod，进入 pod 中执行命令等。你还可以使用 YAML 文件定义资源对象，然后使用 kubectl 将其应用到集群中。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-中的自动扩展&#34;&gt;Kubernetes 中的自动扩展&lt;/h2&gt;
&lt;p&gt;请记住，我们使用 Kubernetes 而不是直接使用 Docker 的原因之一，是因为 Kubernetes 能够自动扩展应用实例的数量以满足工作负载的需求。&lt;/p&gt;
&lt;p&gt;自动缩放是通过集群设置来实现的，当服务需求增加时，增加节点数量，当需求减少时，则减少节点数量。但也要记住，节点是 “物理” 结构 —— 我们把 “物理” 放在引号里，因为要记住，很多时候，它们实际上是虚拟机。&lt;/p&gt;
&lt;p&gt;无论如何，节点是物理机器的事实意味着我们的云平台必须允许 Kubernetes 引擎创建新机器。各种云提供商对 Kubernetes 支持基本都满足这一点。&lt;/p&gt;
&lt;p&gt;我们再继续说一些概念，这次是和网络有关的。&lt;/p&gt;
&lt;h2 id=&#34;什么是-kubernetes-ingress-和-egress&#34;&gt;什么是 kubernetes Ingress 和 Egress？&lt;/h2&gt;
&lt;p&gt;外部用户或应用程序与 Kubernetes pod 交互，就像 pod 是一个真正的服务器一样。我们需要设置安全规则允许哪些流量可以进入和离开 “服务器”，就像我们为托管应用程序的服务器定义安全规则一样。&lt;/p&gt;
&lt;p&gt;进入 Kubernetes pod 的流量称为 Ingress，而从 pod 到集群外的出站流量称为 egress。我们创建入口策略和出口策略的目的是限制不需要的流量进入和流出服务。而这些策略也是定义 pod 使用的端口来接受传入和传输传出数据 / 流量的地方。&lt;/p&gt;
&lt;h2 id=&#34;什么是-ingress-controller&#34;&gt;什么是 Ingress Controller？&lt;/h2&gt;
&lt;p&gt;但是在定义入口和出口策略之前，你必须首先启动被称为 Ingress Controller（入口控制器）的组件；这个在集群中默认不启动。有不同类型的入口控制器，Kubernetes 项目默认只支持 Google Cloud 和开箱即用的 Nginx 入口控制器。通常云供应商都会提供自己的入口控制器。&lt;/p&gt;
&lt;h2 id=&#34;什么是-replica-和-replicaset&#34;&gt;什么是 Replica 和 ReplicaSet？&lt;/h2&gt;
&lt;p&gt;为了保证应用程序的弹性，需要在不同节点上创建多个 pod 的副本。这些被称为 Replica。假设你所需的状态策略是 “让名为 webserver-1 的 pod 始终维持在 3 个副本”，这意味着 ReplicationController 或 ReplicaSet 将监控活动副本的数量，如果其中有任何一个 replica 因任何原因不可用（例如节点的故障），那么 Deployment Controller 将自动创建一个新的系统（定义如下）。&lt;/p&gt;
&lt;p&gt;所需状态是在 deployment 中定义的。 Master 节点的中有一个子系统叫做 Deployment Controller，负责实际执行并使当前状态不断趋向于所需状态。&lt;/p&gt;
&lt;p&gt;因此，举例来说，如果你目前有 2 个 pod 的副本，而你所希望的状态应该有 3 个，那么 Replication Controller 或 ReplicaSet 会自动检测到这个要求，并指示 Deployment Controller 根据预定义的设置部署一个新的 pod。&lt;/p&gt;
&lt;h2 id=&#34;什么是服务网格&#34;&gt;什么是服务网格？&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://jimmysong.io/blog/what-is-a-service-mesh/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;服务网格 (Service Mesh)&lt;/a&gt; 用于管理服务之间的网络流量，是云原生的网络基础设施层，也是 &lt;a href=&#34;https://jimmysong.io/blog/post-kubernetes-era/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes 次世代的云原生应用&lt;/a&gt; 的重要组成部分。&lt;/p&gt;
&lt;p&gt;服务网格利用容器之间的网络设置来控制或改变应用程序中不同组件之间的交互。下面，我们用一个例子来说明。假设你想测试 Nginx 的新版本，检查它是否与你的 Web 应用兼容。你用新的 Nginx 版本创建了一个新的容器 (Container2)，并从当前容器 (Container1) 中复制了当前的 Nginx webserver 配置。但你不想影响组成 web 应用的其他微服务（假设每个容器对应一个单独的微服务）—— 就是 MySQL 数据库、Node.js 前端、负载均衡器等。&lt;/p&gt;
&lt;p&gt;所以使用服务网格，你可以立即只把 webserver 微服务改成 Container2（新 Nginx 版本的那个）进行测试。如果确定它不能工作，比如因为它导致网站出现一些兼容性问题，那么你就调用服务网格来快速切换回原来的 Container1。而这一切都不需要对其他容器进行任何配置变更 —— 这些变更对其他容器是完全透明的。&lt;/p&gt;
&lt;p&gt;如果没有服务网格，对容器来说这项工作将十分繁琐，因为这涉及到逐一更改所有其他容器上的配置，将它们所包含的服务从 Container1 指向 Container2，然后在测试失败后，将它们全部改回来。&lt;/p&gt;
&lt;p&gt;在前面这部分 Kubernetes 指南中，我们介绍了一些与 Kubernetes 网络相关的概念。Kubernetes 中的网络可能很棘手，很难理解，如果你刚刚开始，你可能需要一些实践来理解这里。关于服务网格的更多内容请参考 &lt;a href=&#34;https://jimmysong.io/istio-handbook/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《Istio 服务网格》&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在下一部分中，我们将展开更多关于 Kubernetes 的话题：如何开始学习 Kubernetes，如何在本地安装和测试 Kubernetes，以及 Kubernetes 的一些优秀的监控工具。&lt;/p&gt;
&lt;h2 id=&#34;如何学习-kubernetes&#34;&gt;如何学习 Kubernetes？&lt;/h2&gt;
&lt;p&gt;自学 Kubernetes 知识基本上有三种不同的途径，我们在这里只提供了一个指导大纲。&lt;/p&gt;
&lt;h3 id=&#34;一从零开始学习和安装-kubernetes&#34;&gt;一、从零开始学习和安装 Kubernetes&lt;/h3&gt;
&lt;p&gt;要想真正掌握 Kubernetes，最好的办法莫过于自己从头开始安装 Kubernetes。不过要注意的是，从零开始安装 Kubernetes 并不是一件容易的事情。安装 Kubernetes 并不是简单的 “下载文件 -&amp;gt; 点击安装” 式的操作，Kubernetes 由多个组件组成，这些组件必须单独安装和配置。而在此之前，你也需要相当的技术储备来做安装前的准备，比如熟悉 Linux 操作系统。如果你决定使用这种方式学习的话，推荐你阅读 &lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes Handbook——Kubernetes 中文指南 / 云原生架构实践手册&lt;/a&gt;。此外，请记住，尽管 Kubernetes 作为一个开源解决方案在技术上是免费的，但它确实有一些隐藏的成本，只不过对初学者来说可能并不明显。&lt;/p&gt;
&lt;h3 id=&#34;二kubernetes-自托管解决方案&#34;&gt;二、Kubernetes 自托管解决方案&lt;/h3&gt;
&lt;p&gt;这些解决方案样是一些工具和实用程序，大大简化了在本地计算机上安装和配置小型 Kubernetes 集群的任务。它们是学习 Kubernetes 的好方法，同时对于新手来说也不会太难，又足够小巧可以到安装在个人电脑上。最流行的自托管 Kubernetes 工具和环境是 &lt;a href=&#34;https://github.com/kubernetes/minikube&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Minikube&lt;/a&gt;、&lt;a href=&#34;https://github.com/ubuntu/microk8s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MicroK8s&lt;/a&gt;、&lt;a href=&#34;https://docs.docker.com/docker-for-windows/kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker Desktop&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/kubernetes-sigs/kind&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kind&lt;/a&gt;。这些解决方案往往有一些限制，例如，Minikube 只允许创建一个节点。尽管有这些缺点，但这些工具还是非常值得推荐，因为它们将易学性和成本效益结合起来，对于刚开始使用 Kubernetes 的初学者来说，是一个很好的选择。&lt;/p&gt;
&lt;h3 id=&#34;三云托管的解决方案&#34;&gt;三、云托管的解决方案&lt;/h3&gt;
&lt;p&gt;如今各大云供应商都提供了定制化的 Kubernetes 解决方案来。你也可以通过线上教学平台如 &lt;a href=&#34;https://katacoda.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Katacoda&lt;/a&gt; 上的免费课程来学习 Kubernetes，它们都是云托管的，你不需要自己安装，只不过你需要云供应商的集群需要付费。&lt;/p&gt;
&lt;h2 id=&#34;本地测试和调试-kubernetes&#34;&gt;本地测试和调试 Kubernetes&lt;/h2&gt;
&lt;p&gt;作为本地安装 Kubernetes 的一部分，你很可能还需要一些测试和调试能力，以确保一切都在顺利运行，特别是定义入口和出口策略等棘手的任务。此外，还有 Kubernetes 附加组件的生态系统，你可能想使用这些组件来扩展 Kubernetes 集群的功能。添加所有这些都需要进行更多的测试，以确保它们能与你的 Kubernetes 集群完美的集成。&lt;/p&gt;
&lt;p&gt;用于在本地开发和调试 Kubernetes 服务的工具有：&lt;a href=&#34;https://github.com/microsoft/mindaro&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Microsoft Bridge to Kubernetes&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/telepresenceio/telepresence&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;telepresence&lt;/a&gt;。这些工具可以让你在本地运行单个服务，同时将该服务连接到远程 Kubernetes 集群。这样你就可以让自己的本地机器作为 Kubernetes 集群中的一部分来运行 —— 这对于在本地而不是在生产集群上开发服务非常有用。&lt;/p&gt;
&lt;p&gt;Kubernetes 项目也了解到了 Kubernetes 安装对端到端 (E2E) 测试的需求。为此，项目核心团队一直在确保在最近的版本中更恰当地支持 E2E 测试。这包括诸如允许测试重用和纳入更多附加组件和驱动程序的测试等。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-监控工具&#34;&gt;Kubernetes 监控工具&lt;/h2&gt;
&lt;p&gt;Kubernetes 提供了应用程序在集群的每个层次上的资源使用情况的详细信息 —— 容器、pod、服务。这些详细信息使你能够评估应用程序的性能，确定哪些瓶颈可以解决以提高整体性能。&lt;/p&gt;
&lt;p&gt;毕竟，监控可以帮助你了解应用和集群运行情况的详细信息，这对于学习 Kubernetes 是十分有帮助的。&lt;/p&gt;
&lt;p&gt;Kubernetes 包含两个内置度量收集工具用于监控：资源管道和全度量管道。资源管道是一个较低级和较有限的工具，主要集中在与各种控制器相关的指标上。全指标管道，顾名思义，从几乎所有集群组件中获取并显示更丰富的指标。&lt;/p&gt;
&lt;p&gt;还有一些第三方工具可以安装并集成到 Kubernetes 集群中。对于 Kubernetes 来说，最普遍使用的两个工具是 Prometheus 和 Grafana。&lt;/p&gt;
&lt;h3 id=&#34;prometheus-监控&#34;&gt;Prometheus 监控&lt;/h3&gt;
&lt;p&gt;Prometheus 是一个功能丰富的开源监控和警报工具。Prometheus 包含一个内部数据存储用来收集指标，如生成的时间序列数据。Prometheus 还拥有众多插件，允许它将数据暴露给各种外部解决方案，并从其他数据源导入数据，包括所有主要公有云监控解决方案。&lt;/p&gt;
&lt;h3 id=&#34;grafana-仪表盘&#34;&gt;Grafana 仪表盘&lt;/h3&gt;
&lt;p&gt;Grafana 是一个优秀的仪表盘、分析和数据可视化工具。它没有 Prometheus 的全功能数据收集能力，但 Prometheus 又没有 Grafana 的数据呈现界面。事实上，他们最好是结合在一起使用 ——Prometheus 负责数据收集和汇总，Grafana 负责数据展示。它们共同创造了一个强大的组合，涵盖了数据收集、基本警报和可视化。&lt;/p&gt;
&lt;h3 id=&#34;高级警报&#34;&gt;高级警报&lt;/h3&gt;
&lt;p&gt;对于高级警报，你可以添加 &lt;a href=&#34;https://www.nagios.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nagios&lt;/a&gt; 或 &lt;a href=&#34;https://github.com/prometheus/alertmanager&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prometheus Alertmanager&lt;/a&gt; 等工具。这些警报工具通常有大量的集成。你可以为自定义值班团队，然后定义你想要监控的参数，例如 “当任何 pod 不可用时” 或 “当任何节点无法访问时”、“当容量达到 90%” 等，然后通过电子邮件、短信、手机应用提醒、电话呼叫等方式向值班人员发送自定义通知。你还可以创建升级策略，比如，如果一个被定义为 “危急” 的警报在 10 分钟内没有值班人员确认，那么就将警报升级（发送警报）到该人员的经理。&lt;/p&gt;
&lt;p&gt;现在，你应该已经对 Docker 和 Kubernetes 有了大体的认识。了解了 Kubernetes 的作用，知道它是如何进行容器化应用部署和管理的。&lt;/p&gt;
&lt;p&gt;调试和监控技术不仅仅是运维需要，你也可以把它当作学习方式。有什么比边做边学更好呢？&lt;/p&gt;
&lt;p&gt;请记住，如果你的应用规模太小，而且预计用户需求不会有太大变化或重大波动（比如一个只在公司内部使用的应用），那么 Kubernetes 对你来说可能没有必要，这种情况下，直接使用 Docker 就足够了。&lt;/p&gt;
&lt;h2 id=&#34;更多&#34;&gt;更多&lt;/h2&gt;
&lt;p&gt;云原生领域的开源项目众多（见 &lt;a href=&#34;https://jimmysong.io/awesome-cloud-native&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Awesome Cloud Native / 云原生开源项目大全&lt;/a&gt;），其中有大量的优秀项目可供我们学习。此外，Kubernetes 开源已经多年时间，网上有大量的学习资料，业界出版过很多&lt;a href=&#34;https://jimmysong.io/cloud-native/note/books/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;书籍&lt;/a&gt;，建议大家通过阅读&lt;a href=&#34;https://kubernetes.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;官方文档&lt;/a&gt;和实践来学习，也可以参考我编写的 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes Handbook——Kubernetes 中文指南 / 云原生架构实践手册&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;推荐大家加入笔者发起创办的&lt;a href=&#34;https://cloudnative.to/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生社区&lt;/a&gt;，这是一个立足中国，放眼世界的云原生终端用户社区，致力于云原生技术的传播和应用。云原生社区主办的&lt;a href=&#34;https://github.com/cloudnativeto/academy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生学院&lt;/a&gt;定期邀请云原生和开源领域的大咖进行直播分享，成员自发组织了多个 SIG（特别兴趣小组）进行讨论学习。欢迎加入我们，共同学习和交流云原生技术。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jimmysong.io/docs/cloud-native/intro/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://jimmysong.io/docs/cloud-native/intro/certification/</guid>
      <description>&lt;h1 id=&#34;认证及培训&#34;&gt;认证及培训&lt;/h1&gt;
&lt;p&gt;随着云原生生态的不断发展壮大，业界缺乏相应的人才储备及知识积累，各种认证及培训则如雨后春笋般出现。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jimmysong.io/docs/cloud-native/intro/the-future-of-cloud-native/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://jimmysong.io/docs/cloud-native/intro/the-future-of-cloud-native/</guid>
      <description>&lt;h1 id=&#34;云原生的未来&#34;&gt;云原生的未来&lt;/h1&gt;
&lt;p&gt;注：本文是笔者于 2018 年 5 月 20 日在&lt;a href=&#34;https://www.bagevent.com/event/1233659&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;第四届南京全球技术周&lt;/a&gt;上【互联网技术专场】上的题为【云原生应用的下一站】的演讲的部分内容的文字整理而成。&lt;/p&gt;
&lt;p&gt;要想搞明云原生的未来，首先我们要弄明白云原生是什么。CNCF 最初给出的&lt;a href=&#34;https://github.com/cncf/toc/blob/main/DEFINITION.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;定义&lt;/a&gt;是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容器化&lt;/li&gt;
&lt;li&gt;微服务&lt;/li&gt;
&lt;li&gt;容器可以动态调度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我认为云原生实际上是一种理念或者说是方法论，它包括如下四个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容器化：作为应用包装的载体&lt;/li&gt;
&lt;li&gt;持续交付：利用容器的轻便的特性，构建持续集成和持续发布的流水线&lt;/li&gt;
&lt;li&gt;DevOps：开发与运维之间的协同，上升到一种文化的层次，能够让应用快速的部署和发布&lt;/li&gt;
&lt;li&gt;微服务：这是应用开发的一种理念，将单体应用拆分为微服务才能更好的实现云原生，才能独立的部署、扩展和更新&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一句话解释什么是云原生应用：云原生应用就是为了在云上运行而开发的应用。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes云原生操作系统&#34;&gt;Kubernetes：云原生操作系统&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr4z08j6oj31p20w2n6n.jpg&#34; alt=&#34;Kubernetes 云原生的操作系统&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;要运行这样的应用必须有一个操作系统，就像我们运行PC或手机应用一样，而Kubernetes就是一个这样的操作系统。&lt;/p&gt;
&lt;p&gt;我们再来看下操作系统包括哪些层次。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr52hl4eaj31qy15en74.jpg&#34; alt=&#34;操作系统层次&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;硬件管理：可以管理CPU、内存、网络和存储&lt;/li&gt;
&lt;li&gt;设备接口、虚拟化工具、实用工具&lt;/li&gt;
&lt;li&gt;Shell、用户界面&lt;/li&gt;
&lt;li&gt;各种终端工具，如awk、sort、grep、vim等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是CNCF给出的云原生景观图。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr53j3aiuj32fs1dc7wi.jpg&#34; alt=&#34;云原生景观图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;该图中包括云原生的各种层次的提供者和应用，通过该图可以组合出一些列的云原生平台。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IaaS云提供商（公有云、私有云）&lt;/li&gt;
&lt;li&gt;配置管理，提供最基础的集群配置&lt;/li&gt;
&lt;li&gt;运行时，包括存储和容器运行时、网络等&lt;/li&gt;
&lt;li&gt;调度和管理层，协同和服务发现、服务管理&lt;/li&gt;
&lt;li&gt;应用层&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也可以有平台提供以上所有功能，还可以有提供可观测性、分析和扩展应用。&lt;/p&gt;
&lt;p&gt;看到这个景观图，大家觉得Kubernetes真的还只做了容器编排吗？实际上它是制定了一个标准。就像一个系统一样，所有的应用和插件都是基于它来构建的。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes的现状与未来&#34;&gt;Kubernetes的现状与未来&lt;/h2&gt;
&lt;p&gt;Kubernetes发展已经有3年多的时间了，它已经基本成为了容器编排调度框架的标准。它的各种抽象与资源定义已经被大家广为接受。其中最基础的调度单元Pod。&lt;/p&gt;
&lt;p&gt;创建一个自定义资源类型需要满足的条件。&lt;/p&gt;
&lt;p&gt;这是KubeVirt的架构图。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr54de5oyj31qw14qn2x.jpg&#34; alt=&#34;KubeVirt架构图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们看到图中有两个是Kubernetes原生的组件，API server和kubelet，我们创建了virt-controller就是为了创建CRD的controller，它扩展了kube-controller的功能，用于管理虚拟机的生命周期，同时在每个节点上都用DaemonSet的方式运行一个virt-handler，这个handler是用于创建虚拟机的处理器，每个节点上即可用运行虚拟机也可以运行容器，只要这个节点上有virt-handler就可以运行和调度虚拟机。&lt;/p&gt;
&lt;h3 id=&#34;kubernetes做了什么&#34;&gt;Kubernetes做了什么？&lt;/h3&gt;
&lt;p&gt;Kubernetes优秀的分布式架构设计，给我们提供了众多了可扩展接口，可以让我们很方便的扩展自己的运行时、网络和存储插件，同时还可以通过CRD管理我们自己的分布式应用。它的声明式配置方式可以让我们利用Kubernetes的原语快速的编排出一个云原生应用。&lt;/p&gt;
&lt;p&gt;Kubernetes的资源隔离也能保证对集群资源的最大化和最优利用率。&lt;/p&gt;
&lt;p&gt;下图中展示了Kubernetes中的资源隔离层次。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr54ztql2j329q0zwwlf.jpg&#34; alt=&#34;Kubernetes中的资源隔离&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容器&lt;/li&gt;
&lt;li&gt;Pod：命名空间的隔离，共享网络，每个Pod都有独立IP，使用Service Account为Pod赋予账户&lt;/li&gt;
&lt;li&gt;Sandbox：是对最小资源调度单位的抽象，甚至可以是虚拟机&lt;/li&gt;
&lt;li&gt;Node：网络隔离，每个节点间网络是隔离的，每个节点都有单独的IP地址&lt;/li&gt;
&lt;li&gt;Cluster：元数据的隔离，使用Federation可以将不同的集群联合在一起&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes中的基本资源类型分成了三类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;部署：Deploymnt、ReplicaSet、StatefulSet、DaemonSet、Job、CronJob&lt;/li&gt;
&lt;li&gt;服务：Service、Ingress&lt;/li&gt;
&lt;li&gt;存储：PV、PVC、ConfigMap、Secret&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在最近一届的KubeCon &amp;amp; CloudNativeCon上Operator已经变得越来越流行。下面是OpenEBS的一个使用Operator的例子。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr56m7z2sj31y010y17y.jpg&#34; alt=&#34;OpenEBS 控制平面架构&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;OpenEBS是一款容器化存储，它基于Ceph构建，容器化存储最大的好处就是复用Kubernetes的资源类型，简化存储应用的部署，将单体的存储拆分为“微服务化”的存储，即每个应用在声明PV的时候才会创建存储，并与PV的生命周期一样都是独立于应用的。&lt;/p&gt;
&lt;p&gt;OpenEBS的存储也是分控制平面和数据平面的，下图是OpenEBS的架构图。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr57nm2mnj31xk11qqej.jpg&#34; alt=&#34;OpenEBS 的存储卷管理&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;黄色部分是OpenEBS的组件（除了kube-dashboard），它是使用Kubernetes的各种原语和CRD来创建的，架构跟Kubernetes本身也很类似。&lt;/p&gt;
&lt;p&gt;用户在使用OpenEBS的StorageClass创建PV的时候，OpenEBS会为每个PV创建一个用户管理该PV的Deployment，这个Deployment再来创建存储副本，每个PV的存储副本都可以不同，这取决的用户如何定义的StorageClass。这样就可以将原来的单体存储拆分为微服务化的存储。&lt;/p&gt;
&lt;p&gt;上面说到了Operator的一个应用，下面再来看一个我们之前在Kubernetes中部署Hadoop YARN和Spark的例子。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr58ebf2lj323o11219r.jpg&#34; alt=&#34;Hadoop YARN 迁移到 Kubernetes的示例&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr59gzzwsj32gg16k4qp.jpg&#34; alt=&#34;Spark on Yarn with Kubernetes&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Kubernetes始于12因素应用的PaaS平台，它是微服务的绝佳部署管理平台，基于它可以应用多种设计模式。它的未来将变成什么样呢？&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr5arzvetj31no12mdre.jpg&#34; alt=&#34;云原生与12因素应用&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Service Mesh：解决微服务治理问题&lt;/li&gt;
&lt;li&gt;Auto Pilot：自动驾驭能力，服务自动扩展，智能运维&lt;/li&gt;
&lt;li&gt;FaaS/Serverless：用户无需再关注底层平台，只需要部署服务，根据服务的资源消耗和使用时间付费&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Serverless的发展&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了实现上述的各种能力，急需解决的就是基于Kubernetes的持续集成和发布问题。&lt;/p&gt;
&lt;p&gt;当前出现了一系列的基于Kubernetes的CI/CD工具，如Jenkins-x、Gitkube，它提供了从代码提交、自动编译、打包镜像、配置注入、发布部署到Kubernetes平台的一系列自动化流程。&lt;/p&gt;
&lt;p&gt;甚至出现了像ballerina这样的云原生编程语言，它的出现就是为了解决应用开发到服务集成之间的鸿沟的。它有以下几个特点。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr5c8bwmtj31ou152qc3.jpg&#34; alt=&#34;云原生编程语言&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用云原生语义的DSL&lt;/li&gt;
&lt;li&gt;注解式配置&lt;/li&gt;
&lt;li&gt;序列图式操作&lt;/li&gt;
&lt;li&gt;支持微服务的治理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要完成云的集成CI/CD，或者用一个词代替来说就是GitOps的需求越来越强烈。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr5bulhuhj329m10iwua.jpg&#34; alt=&#34;Gitkube&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;kubernetes没有做什么&#34;&gt;Kubernetes没有做什么&lt;/h3&gt;
&lt;p&gt;看下这张图中的两个服务，它们使用的是kube-proxy里基于iptables的原生的负载均衡，并且服务间的流量也没有任何控制。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr5dsurx6j320i140tpf.jpg&#34; alt=&#34;Kuberentes中的流量管理&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Kubernetes缺少的最重要的一个功能就是微服务的治理，微服务比起单体服务来说使得部署和运维起来更加复杂，对于微服务的可观测性也有更高的要求，同时CI/CD流程Kubernetes本身也没有提供。&lt;/p&gt;
&lt;h2 id=&#34;service-mesh&#34;&gt;Service Mesh&lt;/h2&gt;
&lt;p&gt;Service Mesh是一个专用的基础设施层，它能够将微服务的治理层应用层下沉到基础设施层，将原来开发人员很多活给分担出去，让开发人员更注重业务逻辑和应用的性能本身，将服务治理的能力交给平台来解决。使用Service Mesh能够提供安全的服务间通讯、在服务间通讯应用各种策略实现灰度发布、流量切分等功能，它还能适配多语言，让微服务应用无感知的迁移到云原生。&lt;/p&gt;
&lt;p&gt;这是Istio在Kubenetes中创建的各种CRD，这些CRD有些是作为路由策略、有些是做监控指标和权限控制的。&lt;/p&gt;
&lt;p&gt;这是Istio Service Mesh的架构图。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr5exqm7kj320u18mh2t.jpg&#34; alt=&#34;Istio Service Mesh架构图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pilot：提供用户接口，用户可以通过该接口配置各种路由规则，Pilot还可以通过适配器获取平台上各种服务之间的管理，Evnoy这个使用Sidecar方式部署到每个应用pod中的进程会通过Pilot中的Envoy API获得平台上各个服务之间的管理，同时也会应用用户配置的路由规则。&lt;/li&gt;
&lt;li&gt;Mixer：获取各种平台属性，服务间通讯时会先访问Mixer兼容各平台的属性信息，如quota、访问控制和策略评估，将服务间的访问信息记录后上报到mixer形成遥测报告。&lt;/li&gt;
&lt;li&gt;每个Pod上还有SA和SPIFFE做权限管控。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Service Mesh实际上为了解决社会分工问题，它本身是为了解决微服务的治理。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/00704eQkgy1frr5fxzoltj32f81akqr2.jpg&#34; alt=&#34;Service Mesh架构&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Pilot和控制平面是为了运维人员准备的。&lt;/p&gt;
&lt;p&gt;数据平面是为开发人员准备的。&lt;/p&gt;
&lt;p&gt;Isito在每个上下游服务之间部署一个Envoy，Envoy中有几个基本的服务发现服务，监听器即Envoy要转发的流量端口，Endpoint是要转发的目的地，Cluster是一系列Endpoint用来做负载均衡，Route是定义各种路由规则，每个Envoy进程里可以设置多个Listener。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/envoy-arch.png&#34; alt=&#34;Envoy proxy架构图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;云原生是在云计算发展到一定阶段的产物，它的方兴未艾，未来我们会看到更多优秀的云原生技术的出现。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
